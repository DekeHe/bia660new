{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f9251fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['noise', 'music']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from operator import itemgetter\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import csv\n",
    "import nltk\n",
    "import numpy\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "\n",
    "\n",
    "def parse(input_path,index1,index2):\n",
    "    attributes=['sound','headphone','quality',\n",
    "                'noise','bass','music','battery']\n",
    "\n",
    "    def getGa(s):\n",
    "        ga=set()\n",
    "        f=open(s)\n",
    "        for v in f:\n",
    "            ga.add(v.strip())\n",
    "        return ga\n",
    "\n",
    "    ga=getGa( 'positive-words.txt')\n",
    "    ba=getGa(  'negative-words.txt')\n",
    "\n",
    "    f=open(input_path)\n",
    "    reader=csv.reader(f)\n",
    "    l=list(reader)\n",
    "    p1=l[index1][0]\n",
    "    p2=l[index2][0]\n",
    "\n",
    "    def getM1(p1):\n",
    "\n",
    "        m1={}\n",
    "\n",
    "        sentences=sent_tokenize(p1)\n",
    "        for sentence in sentences:\n",
    "            nouns=set()\n",
    "            count=0\n",
    "\n",
    "            words=word_tokenize(sentence)\n",
    "            tWords=nltk.pos_tag(words)\n",
    "            for t in tWords:\n",
    "                if t[1].startswith('NN'):\n",
    "                    noun=t[0].lower()\n",
    "                    nouns.add(noun)\n",
    "\n",
    "                    if noun not in m1:\n",
    "                        m1[noun]=[0,0]\n",
    "\n",
    "            for t in tWords:\n",
    "                if t[1]. startswith('JJ'):\n",
    "                    if t [0] in ga:\n",
    "                        count+=1\n",
    "                    elif t[0] in ba:\n",
    "                        count-=1\n",
    "            if count>0:\n",
    "                for noun in nouns: m1[noun][0]+=1\n",
    "            elif count< 0 :\n",
    "                for noun in nouns:m1[noun][1]+=1\n",
    "\n",
    "        return m1\n",
    "\n",
    "    m1=getM1(p1)\n",
    "    m2=getM1(p2)\n",
    "\n",
    "    r1=[]\n",
    "    r2=[]\n",
    "    for v in attributes:\n",
    "        if v in m1:\n",
    "            r1.append([v,m1[v],m1[v][1]-m1[v][0]])\n",
    "        else:\n",
    "            r1.append([v,[0,0],0])\n",
    "        if v  in m2:\n",
    "            r2.append([v,m2[v],m2[v][1]-m2[v][0]])\n",
    "        else:\n",
    "            r2.append([v,[0,0],0])\n",
    "\n",
    "    r=[]\n",
    "    for i in range(0,len(r1)):\n",
    "        if r1[i][2] *r2[i] [2]<0:\n",
    "            r.append(r1[i][0])\n",
    "\n",
    "\n",
    "    # print(r1)\n",
    "    # print(r2)\n",
    "    return r\n",
    "\n",
    "r=parse('amazonreviews.csv',9,12)\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
